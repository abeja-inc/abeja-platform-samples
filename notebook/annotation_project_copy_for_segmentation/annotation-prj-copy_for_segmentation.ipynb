{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "from tqdm import notebook\n",
    "import time\n",
    "import yaml\n",
    "from PIL import Image\n",
    "import json\n",
    "import re\n",
    "\n",
    "from abeja.datalake import APIClient\n",
    "from abeja.datalake import Client as DatalakeClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOTATION_JSON_NAME = 'XXXXXXXXXXXX.json'\n",
    "api_client = APIClient()\n",
    "\n",
    "page = 1\n",
    "delay = 3\n",
    "\n",
    "# get credential information\n",
    "yaml_dict = yaml.load(open('secret.yaml').read(), Loader=yaml.SafeLoader)\n",
    "\n",
    "# set credential\n",
    "organization_id = yaml_dict['organization_id']\n",
    "user_id = yaml_dict['user_id']\n",
    "personal_access_token = yaml_dict['personal_access_token']\n",
    "\n",
    "credential = {\n",
    "    'user_id': user_id,\n",
    "    'personal_access_token': personal_access_token\n",
    "}\n",
    "\n",
    "# set credential for preinference\n",
    "annotation_user_id = yaml_dict['annotation_user_id']\n",
    "annotation_access_token = yaml_dict['annotation_access_token']\n",
    "annotation_organization_id = yaml_dict['annotation_organization_id']\n",
    "annotation_project_id = yaml_dict['annotation_project_id']\n",
    "\n",
    "headers = {\n",
    "    'api-access-user-id': annotation_user_id,\n",
    "    'api-access-token': annotation_access_token\n",
    "}\n",
    "\n",
    "# get DataLake channel id in and out\n",
    "annotation_api = 'https://annotation-tool.abeja.io'\n",
    "project_url = urljoin(annotation_api, '/api/v1/organizations/{}/projects/{}'.format(annotation_organization_id,\n",
    "                                                                                    annotation_project_id))\n",
    "res_project_url = requests.get(project_url, headers=headers)\n",
    "res_project_url.raise_for_status()\n",
    "channel_id_in = res_project_url.json()['data_lake_channels'][0]['channel_id']\n",
    "channel_id_out = res_project_url.json()['result_data_lake_channel']['channel_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "        # get annotation tasks\n",
    "        task_url = urljoin(annotation_api, '/api/v1/organizations/{}/projects/{}/tasks/'.format(\n",
    "            annotation_organization_id, annotation_project_id))\n",
    "        res_task_url = requests.get(task_url,\n",
    "                                    headers=headers,\n",
    "                                    params={'page': page})\n",
    "        res_task_url.raise_for_status()\n",
    "\n",
    "        # check if project has data\n",
    "        if len(res_task_url.json()) == 0:\n",
    "            break\n",
    "\n",
    "        f = open(ANNOTATION_JSON_NAME,'r')\n",
    "        json_dict = json.load(f)\n",
    "            \n",
    "        for task in tqdm(res_task_url.json()):\n",
    "            # load image from DataLake channel-in\n",
    "            client = DatalakeClient(organization_id=organization_id, credential=credential)\n",
    "            channel = client.get_channel(channel_id_in)\n",
    "            metadata = task['metadata'][0]\n",
    "            input_img = channel.get_file(metadata['file_id'])\n",
    "            content_type = input_img.get_file_info()['content_type']\n",
    "            input_img_io = io.BytesIO(input_img.get_content())\n",
    "            input_img_fike_id = metadata['file_id']\n",
    "\n",
    "            information = []\n",
    "            \n",
    "            for x in json_dict:\n",
    "                search_data = x['task']['metadata']\n",
    "                search_in = [d for d in search_data if 'source' in d]\n",
    "                search_str = ','.join(map(str,search_in))\n",
    "                search_name_pick = search_str.split(',', 15)[3]\n",
    "                search_name = search_name_pick.split(':', 2)[1]\n",
    "                search = search_name.strip(\"'\"\" '\")\n",
    "                \n",
    "                if input_img_fike_id == search:\n",
    "                        \n",
    "                    annotation_data = x['information']\n",
    "\n",
    "            \n",
    "                    origin_in = [d for d in annotation_data ]\n",
    "                    origin_str = ','.join(map(str,origin_in))\n",
    "                \n",
    "                    annotation_data.pop()\n",
    "                \n",
    "                    for s in annotation_data:\n",
    "                        i = 0    \n",
    "                        if 'id' in s:\n",
    "                                       \n",
    "                            file_id_pick_str = s['file_id']\n",
    "                \n",
    "                            # get file url\n",
    "                            file_info_url = 'https://api.abeja.io//channels/{}/{}'.format(channel_id_out, file_id_pick_str)\n",
    "                            res_file_info_url = requests.get(file_info_url,\n",
    "                                                     auth=(user_id, personal_access_token))\n",
    "                            res_file_info_url.raise_for_status()\n",
    "                            file_url = res_file_info_url.json()['download_url']\n",
    "\n",
    "                            # information_list\n",
    "                            information.append({\n",
    "                                'class': s['class'],\n",
    "                                'color': s['color'],\n",
    "                                'file_id': s['file_id'],\n",
    "                                'file_url': file_url,\n",
    "                                'id': s['id']}\n",
    "                            )\n",
    "                            \n",
    "                    # register predicted result to annotation tool\n",
    "                    preinference_url = urljoin(task_url, \"{}/preinferences\".format(str(task['id'])))\n",
    "                    res_preinference_url = requests.post(preinference_url,\n",
    "                                                            json={'information': information},\n",
    "                                                            headers=headers)\n",
    "                    res_preinference_url.raise_for_status()\n",
    "                    \n",
    "                    #print(res_preinference_url.json())\n",
    "                    time.sleep(delay)\n",
    "                                    \n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "        page = page + 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
